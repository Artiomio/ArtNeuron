NetworkOne constructor has been run!
Number of neurons in the output layer: 1

setTrainingSet: setting data set
Number of training examples : 8

Caution: Default mini-batch covers the whole data set
The method setTrainingSet() is supposed to run once
Initializing weights with normal randoms
Iteration: 0 loss= 0.11024261496815516
Iteration: 1 loss= 0.08713826284318085
Iteration: 2 loss= 0.07369069921369434
Iteration: 3 loss= 0.06568180816319993
Iteration: 4 loss= 0.06080556623147656
Iteration: 5 loss= 0.057778659402141
Iteration: 6 loss= 0.055868806786835444
Iteration: 7 loss= 0.05464734319104883
Iteration: 8 loss= 0.053857375011719735
Iteration: 9 loss= 0.05334174692383315
Iteration: 10 loss= 0.05300260880075674
Iteration: 11 loss= 0.05277812149425586
Iteration: 12 loss= 0.05262871288535442
Iteration: 13 loss= 0.05252879481128145
Iteration: 14 loss= 0.05246167751637147
Iteration: 15 loss= 0.05241639670934793
Iteration: 16 loss= 0.05238570645154861
Iteration: 17 loss= 0.052364794521563576
Iteration: 18 loss= 0.05235045197407649
Iteration: 19 loss= 0.05234053178434941
Iteration: 20 loss= 0.05233359344685497
Iteration: 21 loss= 0.05232866827091219
Iteration: 22 loss= 0.05232510361697025
Iteration: 23 loss= 0.05232245909661057
Iteration: 24 loss= 0.0523204371638938
Iteration: 25 loss= 0.05231883657145128
Iteration: 26 loss= 0.05231752108563998
Iteration: 27 loss= 0.052316398417199025
Iteration: 28 loss= 0.05231540600885908
Iteration: 29 loss= 0.05231450143557955
Iteration: 30 loss= 0.052313655913275706
Iteration: 31 loss= 0.052312849905515185
Iteration: 32 loss= 0.052312070147914
Iteration: 33 loss= 0.05231130763151749
Iteration: 34 loss= 0.05231055623541797
Iteration: 35 loss= 0.05230981179921192
Iteration: 36 loss= 0.05230907149360476
Iteration: 37 loss= 0.05230833339321086
Iteration: 38 loss= 0.05230759618652842
Iteration: 39 loss= 0.05230685897900653
Iteration: 40 loss= 0.05230612115930469
Iteration: 41 loss= 0.0523053823084564
Iteration: 42 loss= 0.052304642138167746
Iteration: 43 loss= 0.052303900448902825
Iteration: 44 loss= 0.05230315710140909
Iteration: 45 loss= 0.0523024119973723
Iteration: 46 loss= 0.05230166506627317
Iteration: 47 loss= 0.05230091625645766
Iteration: 48 loss= 0.0523001655290695
Iteration: 49 loss= 0.052299412853927876
Iteration: 50 loss= 0.052298658206726134
Iteration: 51 loss= 0.0522979015671286
Iteration: 52 loss= 0.05229714291747705
Iteration: 53 loss= 0.052296382241911875
Iteration: 54 loss= 0.05229561952577481
Iteration: 55 loss= 0.05229485475520285
Iteration: 56 loss= 0.052294087916852326
Iteration: 57 loss= 0.052293318997711086
Iteration: 58 loss= 0.05229254798497099
Iteration: 59 loss= 0.052291774865940846
Iteration: 60 loss= 0.052290999627987264
Iteration: 61 loss= 0.05229022225849429
Iteration: 62 loss= 0.05228944274483568
Iteration: 63 loss= 0.05228866107435604
Iteration: 64 loss= 0.05228787723435779
Iteration: 65 loss= 0.05228709121209209
Iteration: 66 loss= 0.05228630299475262
Iteration: 67 loss= 0.05228551256947098
Iteration: 68 loss= 0.05228471992331352
Iteration: 69 loss= 0.0522839250432791
Iteration: 70 loss= 0.052283127916297134
Iteration: 71 loss= 0.05228232852922627
Iteration: 72 loss= 0.05228152686885329
Iteration: 73 loss= 0.052280722921892106
Iteration: 74 loss= 0.05227991667498288
Iteration: 75 loss= 0.05227910811469139
Iteration: 76 loss= 0.052278297227508215
Iteration: 77 loss= 0.052277483999848134
Iteration: 78 loss= 0.05227666841804941
Iteration: 79 loss= 0.05227585046837322
Iteration: 80 loss= 0.05227503013700297
Iteration: 81 loss= 0.05227420741004375
Iteration: 82 loss= 0.05227338227352156
Iteration: 83 loss= 0.05227255471338291
Iteration: 84 loss= 0.05227172471549392
Iteration: 85 loss= 0.05227089226563991
Iteration: 86 loss= 0.05227005734952465
Iteration: 87 loss= 0.05226921995276976
Iteration: 88 loss= 0.05226838006091404
Iteration: 89 loss= 0.05226753765941283
Iteration: 90 loss= 0.05226669273363735
Iteration: 91 loss= 0.052265845268874046
Iteration: 92 loss= 0.05226499525032392
Iteration: 93 loss= 0.05226414266310186
Iteration: 94 loss= 0.05226328749223591
Iteration: 95 loss= 0.0522624297226667
Iteration: 96 loss= 0.05226156933924661
Iteration: 97 loss= 0.052260706326739174
Iteration: 98 loss= 0.0522598406698184
Iteration: 99 loss= 0.05225897235306792
Iteration: 100 loss= 0.052258101360980455
Iteration: 101 loss= 0.05225722767795697
Iteration: 102 loss= 0.052256351288305955
Iteration: 103 loss= 0.052255472176242754
Iteration: 104 loss= 0.052254590325888736
Iteration: 105 loss= 0.05225370572127069
Iteration: 106 loss= 0.052252818346319896
Iteration: 107 loss= 0.05225192818487151
Iteration: 108 loss= 0.05225103522066371
Iteration: 109 loss= 0.052250139437336945
Iteration: 110 loss= 0.05224924081843316
Iteration: 111 loss= 0.052248339347395034
Iteration: 112 loss= 0.052247435007565166
Iteration: 113 loss= 0.052246527782185234
Iteration: 114 loss= 0.05224561765439523
Iteration: 115 loss= 0.052244704607232635
Iteration: 116 loss= 0.052243788623631646
Iteration: 117 loss= 0.05224286968642221
Iteration: 118 loss= 0.05224194777832937
Iteration: 119 loss= 0.0522410228819722
Iteration: 120 loss= 0.05224009497986325
Iteration: 121 loss= 0.05223916405440734
Iteration: 122 loss= 0.05223823008790095
Iteration: 123 loss= 0.052237293062531234
Iteration: 124 loss= 0.052236352960375196
Iteration: 125 loss= 0.05223540976339873
Iteration: 126 loss= 0.05223446345345574
Iteration: 127 loss= 0.052233514012287256
Iteration: 128 loss= 0.05223256142152053
Iteration: 129 loss= 0.05223160566266805
Iteration: 130 loss= 0.05223064671712667
Iteration: 131 loss= 0.05222968456617663
Iteration: 132 loss= 0.05222871919098063
Iteration: 133 loss= 0.052227750572582846
Iteration: 134 loss= 0.05222677869190799
Iteration: 135 loss= 0.05222580352976029
Iteration: 136 loss= 0.0522248250668226
Iteration: 137 loss= 0.05222384328365525
Iteration: 138 loss= 0.05222285816069521
Iteration: 139 loss= 0.05222186967825496
Iteration: 140 loss= 0.052220877816521495
Iteration: 141 loss= 0.05221988255555535
Iteration: 142 loss= 0.052218883875289446
Iteration: 143 loss= 0.05221788175552819
Iteration: 144 loss= 0.05221687617594629
Iteration: 145 loss= 0.05221586711608768
Iteration: 146 loss= 0.052214854555364607
Iteration: 147 loss= 0.05221383847305626
Iteration: 148 loss= 0.052212818848307925
Iteration: 149 loss= 0.052211795660129776
Iteration: 150 loss= 0.05221076888739574
Iteration: 151 loss= 0.05220973850884232
Iteration: 152 loss= 0.052208704503067596
Iteration: 153 loss= 0.05220766684852994
Iteration: 154 loss= 0.05220662552354691
Iteration: 155 loss= 0.052205580506294036
Iteration: 156 loss= 0.05220453177480369
Iteration: 157 loss= 0.052203479306963854
Iteration: 158 loss= 0.052202423080516855
Iteration: 159 loss= 0.05220136307305829
Iteration: 160 loss= 0.052200299262035635
Iteration: 161 loss= 0.052199231624747114
Iteration: 162 loss= 0.05219816013834035
Iteration: 163 loss= 0.052197084779811206
Iteration: 164 loss= 0.052196005526002405
Iteration: 165 loss= 0.052194922353602305
Iteration: 166 loss= 0.052193835239143525
Iteration: 167 loss= 0.05219274415900169
Iteration: 168 loss= 0.05219164908939412
Iteration: 169 loss= 0.05219055000637836
Iteration: 170 loss= 0.052189446885850976
Iteration: 171 loss= 0.05218833970354612
Iteration: 172 loss= 0.052187228435034115
Iteration: 173 loss= 0.05218611305572007
Iteration: 174 loss= 0.052184993540842564
Iteration: 175 loss= 0.052183869865472104
Iteration: 176 loss= 0.052182742004509716
Iteration: 177 loss= 0.052181609932685565
Iteration: 178 loss= 0.0521804736245574
Iteration: 179 loss= 0.05217933305450907
Iteration: 180 loss= 0.052178188196749194
Iteration: 181 loss= 0.05217703902530939
Iteration: 182 loss= 0.052175885514042925
Iteration: 183 loss= 0.052174727636623244
Iteration: 184 loss= 0.05217356536654216
Iteration: 185 loss= 0.05217239867710852
Iteration: 186 loss= 0.052171227541446534
Iteration: 187 loss= 0.05217005193249415
Iteration: 188 loss= 0.052168871823001464
Iteration: 189 loss= 0.052167687185529096
Iteration: 190 loss= 0.05216649799244656
Iteration: 191 loss= 0.05216530421593052
Iteration: 192 loss= 0.05216410582796319
Iteration: 193 loss= 0.05216290280033057
Iteration: 194 loss= 0.052161695104620806
Iteration: 195 loss= 0.052160482712222345
Iteration: 196 loss= 0.05215926559432237
Iteration: 197 loss= 0.05215804372190479
Iteration: 198 loss= 0.05215681706574862
Iteration: 199 loss= 0.052155585596426184
Iteration: 200 loss= 0.05215434928430116
Iteration: 201 loss= 0.052153108099526904
Iteration: 202 loss= 0.05215186201204442
Iteration: 203 loss= 0.05215061099158067
Iteration: 204 loss= 0.052149355007646475
Iteration: 205 loss= 0.05214809402953478
Iteration: 206 loss= 0.05214682802631858
Iteration: 207 loss= 0.052145556966849055
Iteration: 208 loss= 0.052144280819753544
Iteration: 209 loss= 0.05214299955343353
Iteration: 210 loss= 0.052141713136062764
Iteration: 211 loss= 0.05214042153558496
Iteration: 212 loss= 0.05213912471971202
Iteration: 213 loss= 0.05213782265592179
Iteration: 214 loss= 0.05213651531145597
Iteration: 215 loss= 0.052135202653318065
Iteration: 216 loss= 0.05213388464827112
Iteration: 217 loss= 0.05213256126283569
Iteration: 218 loss= 0.052131232463287575
Iteration: 219 loss= 0.05212989821565557
Iteration: 220 loss= 0.05212855848571931
Iteration: 221 loss= 0.05212721323900697
Iteration: 222 loss= 0.05212586244079299
Iteration: 223 loss= 0.05212450605609574
Iteration: 224 loss= 0.05212314404967521
Iteration: 225 loss= 0.05212177638603073
Iteration: 226 loss= 0.05212040302939836
Iteration: 227 loss= 0.05211902394374882
Iteration: 228 loss= 0.05211763909278474
Iteration: 229 loss= 0.05211624843993842
Iteration: 230 loss= 0.052114851948369234
Iteration: 231 loss= 0.052113449580961146
Iteration: 232 loss= 0.05211204130032021
Iteration: 233 loss= 0.05211062706877198
Iteration: 234 loss= 0.05210920684835886
Iteration: 235 loss= 0.05210778060083762
Iteration: 236 loss= 0.052106348287676636
Iteration: 237 loss= 0.0521049098700533
Iteration: 238 loss= 0.052103465308851155
Iteration: 239 loss= 0.05210201456465742
Iteration: 240 loss= 0.05210055759775999
Iteration: 241 loss= 0.0520990943681448
Iteration: 242 loss= 0.052097624835492885
Iteration: 243 loss= 0.05209614895917767
Iteration: 244 loss= 0.052094666698261946
Iteration: 245 loss= 0.05209317801149502
Iteration: 246 loss= 0.05209168285730979
Iteration: 247 loss= 0.05209018119381972
Iteration: 248 loss= 0.052088672978815864
Iteration: 249 loss= 0.052087158169763836
Iteration: 250 loss= 0.05208563672380062
Iteration: 251 loss= 0.05208410859773166
Iteration: 252 loss= 0.052082573748027536
Iteration: 253 loss= 0.05208103213082088
Iteration: 254 loss= 0.05207948370190312
Iteration: 255 loss= 0.05207792841672127
Iteration: 256 loss= 0.052076366230374586
Iteration: 257 loss= 0.05207479709761131
Iteration: 258 loss= 0.052073220972825275
Iteration: 259 loss= 0.05207163781005253
Iteration: 260 loss= 0.052070047562967875
Iteration: 261 loss= 0.052068450184881376
Iteration: 262 loss= 0.05206684562873498
Iteration: 263 loss= 0.05206523384709879
Iteration: 264 loss= 0.052063614792167624
Iteration: 265 loss= 0.05206198841575726
Iteration: 266 loss= 0.05206035466930086
Iteration: 267 loss= 0.05205871350384523
Iteration: 268 loss= 0.05205706487004709
Iteration: 269 loss= 0.052055408718169174
Iteration: 270 loss= 0.052053744998076586
Iteration: 271 loss= 0.052052073659232714
Iteration: 272 loss= 0.05205039465069543
Iteration: 273 loss= 0.05204870792111308
Iteration: 274 loss= 0.052047013418720464
Iteration: 275 loss= 0.05204531109133484
Iteration: 276 loss= 0.05204360088635171
Iteration: 277 loss= 0.05204188275074075
Iteration: 278 loss= 0.05204015663104154
Iteration: 279 loss= 0.05203842247335941
Iteration: 280 loss= 0.05203668022336105
Iteration: 281 loss= 0.05203492982627025
Iteration: 282 loss= 0.05203317122686336
Iteration: 283 loss= 0.052031404369465004
Iteration: 284 loss= 0.05202962919794351
Iteration: 285 loss= 0.05202784565570633
Iteration: 286 loss= 0.052026053685695475
Iteration: 287 loss= 0.05202425323038283
Iteration: 288 loss= 0.05202244423176551
Iteration: 289 loss= 0.05202062663136096
Iteration: 290 loss= 0.05201880037020231
Iteration: 291 loss= 0.05201696538883334
Iteration: 292 loss= 0.05201512162730359
Iteration: 293 loss= 0.05201326902516343
Iteration: 294 loss= 0.05201140752145894
Iteration: 295 loss= 0.05200953705472677
Iteration: 296 loss= 0.052007657562989106
Iteration: 297 loss= 0.05200576898374829
Iteration: 298 loss= 0.05200387125398152
Iteration: 299 loss= 0.05200196431013569
Iteration: 300 loss= 0.05200004808812175
Iteration: 301 loss= 0.051998122523309265
Iteration: 302 loss= 0.05199618755052099
Iteration: 303 loss= 0.05199424310402706
Iteration: 304 loss= 0.05199228911753953
Iteration: 305 loss= 0.051990325524206384
Iteration: 306 loss= 0.051988352256605905
Iteration: 307 loss= 0.0519863692467407
Iteration: 308 loss= 0.051984376426031716
Iteration: 309 loss= 0.05198237372531225
Iteration: 310 loss= 0.05198036107482189
Iteration: 311 loss= 0.051978338404200165
Iteration: 312 loss= 0.0519763056424805
Iteration: 313 loss= 0.05197426271808368
Iteration: 314 loss= 0.05197220955881168
Iteration: 315 loss= 0.05197014609184095
Iteration: 316 loss= 0.05196807224371594
Iteration: 317 loss= 0.05196598794034253
Iteration: 318 loss= 0.05196389310698119
Iteration: 319 loss= 0.05196178766824019
Iteration: 320 loss= 0.05195967154806878
Iteration: 321 loss= 0.05195754466975016
Iteration: 322 loss= 0.05195540695589436
Iteration: 323 loss= 0.05195325832843124
Iteration: 324 loss= 0.05195109870860308
Iteration: 325 loss= 0.0519489280169574
Iteration: 326 loss= 0.05194674617333942
Iteration: 327 loss= 0.05194455309688466
Iteration: 328 loss= 0.05194234870601123
Iteration: 329 loss= 0.05194013291841216
Iteration: 330 loss= 0.05193790565104768
Iteration: 331 loss= 0.05193566682013723
Iteration: 332 loss= 0.05193341634115151
Iteration: 333 loss= 0.05193115412880436
Iteration: 334 loss= 0.05192888009704466
Iteration: 335 loss= 0.05192659415904788
Iteration: 336 loss= 0.051924296227207754
Iteration: 337 loss= 0.05192198621312784
Iteration: 338 loss= 0.05191966402761277
Iteration: 339 loss= 0.051917329580659574
Iteration: 340 loss= 0.05191498278144896
Iteration: 341 loss= 0.05191262353833614
Iteration: 342 loss= 0.05191025175884198
Iteration: 343 loss= 0.05190786734964365
Iteration: 344 loss= 0.051905470216565434
Iteration: 345 loss= 0.051903060264569305
Iteration: 346 loss= 0.05190063739774532
Iteration: 347 loss= 0.05189820151930204
Iteration: 348 loss= 0.05189575253155666
Iteration: 349 loss= 0.05189329033592518
Iteration: 350 loss= 0.051890814832912316
Iteration: 351 loss= 0.05188832592210138
Iteration: 352 loss= 0.05188582350214385
Iteration: 353 loss= 0.0518833074707491
Iteration: 354 loss= 0.05188077772467369
Iteration: 355 loss= 0.05187823415971078
Iteration: 356 loss= 0.051875676670679154
Iteration: 357 loss= 0.05187310515141232
Iteration: 358 loss= 0.05187051949474729
Iteration: 359 loss= 0.05186791959251341
Iteration: 360 loss= 0.051865305335520785
Iteration: 361 loss= 0.051862676613548826
Iteration: 362 loss= 0.051860033315334404
Iteration: 363 loss= 0.051857375328560024
Iteration: 364 loss= 0.05185470253984179
Iteration: 365 loss= 0.05185201483471709
Iteration: 366 loss= 0.051849312097632355
Iteration: 367 loss= 0.05184659421193037
Iteration: 368 loss= 0.051843861059837744
Iteration: 369 loss= 0.051841112522451875
Iteration: 370 loss= 0.05183834847972798
Iteration: 371 loss= 0.05183556881046581
Iteration: 372 loss= 0.05183277339229633
Iteration: 373 loss= 0.05182996210166813
Iteration: 374 loss= 0.051827134813833435
Iteration: 375 loss= 0.05182429140283448
Iteration: 376 loss= 0.05182143174148918
Iteration: 377 loss= 0.05181855570137674
Iteration: 378 loss= 0.051815663152823266
Iteration: 379 loss= 0.05181275396488694
Iteration: 380 loss= 0.05180982800534309
Iteration: 381 loss= 0.0518068851406691
Iteration: 382 loss= 0.05180392523602896
Iteration: 383 loss= 0.05180094815525786
Iteration: 384 loss= 0.05179795376084624
Iteration: 385 loss= 0.051794941913923954
Iteration: 386 loss= 0.05179191247424394
Iteration: 387 loss= 0.051788865300165875
Iteration: 388 loss= 0.05178580024863936
Iteration: 389 loss= 0.05178271717518727
Iteration: 390 loss= 0.051779615933888384
Iteration: 391 loss= 0.05177649637736011
Iteration: 392 loss= 0.051773358356740816
Iteration: 393 loss= 0.051770201721672036
Iteration: 394 loss= 0.05176702632028039
Iteration: 395 loss= 0.051763831999158974
Iteration: 396 loss= 0.05176061860334902
Iteration: 397 loss= 0.05175738597632087
Iteration: 398 loss= 0.05175413395995475
Iteration: 399 loss= 0.05175086239452145
Iteration: 400 loss= 0.051747571118662544
Iteration: 401 loss= 0.05174425996937046
Iteration: 402 loss= 0.05174092878196808
Iteration: 403 loss= 0.051737577390088316
Iteration: 404 loss= 0.051734205625653146
Iteration: 405 loss= 0.0517308133188525
Iteration: 406 loss= 0.05172740029812275
Iteration: 407 loss= 0.05172396639012499
Iteration: 408 loss= 0.051720511419722864
Iteration: 409 loss= 0.05171703520996026
Iteration: 410 loss= 0.05171353758203842
Iteration: 411 loss= 0.05171001835529303
Iteration: 412 loss= 0.05170647734717071
Iteration: 413 loss= 0.0517029143732053
Iteration: 414 loss= 0.05169932924699379
Iteration: 415 loss= 0.0516957217801718
Iteration: 416 loss= 0.05169209178238885
Iteration: 417 loss= 0.05168843906128315
Iteration: 418 loss= 0.051684763422456016
Iteration: 419 loss= 0.051681064669446046
Iteration: 420 loss= 0.05167734260370276
Iteration: 421 loss= 0.051673597024559856
Iteration: 422 loss= 0.05166982772920821
Iteration: 423 loss= 0.051666034512668275
Iteration: 424 loss= 0.0516622171677623
Iteration: 425 loss= 0.05165837548508588
Iteration: 426 loss= 0.05165450925297929
Iteration: 427 loss= 0.05165061825749824
Iteration: 428 loss= 0.05164670228238434
Iteration: 429 loss= 0.0516427611090349
Iteration: 430 loss= 0.051638794516472575
Iteration: 431 loss= 0.051634802281314215
Iteration: 432 loss= 0.05163078417773949
Iteration: 433 loss= 0.051626739977459
Iteration: 434 loss= 0.05162266944968173
Iteration: 435 loss= 0.05161857236108225
Iteration: 436 loss= 0.05161444847576723
Iteration: 437 loss= 0.051610297555241526
Iteration: 438 loss= 0.05160611935837371
Iteration: 439 loss= 0.05160191364136111
Iteration: 440 loss= 0.05159768015769425
Iteration: 441 loss= 0.051593418658120824
Iteration: 442 loss= 0.051589128890609
Iteration: 443 loss= 0.05158481060031023
Iteration: 444 loss= 0.05158046352952154
Iteration: 445 loss= 0.051576087417647
Iteration: 446 loss= 0.05157168200115897
Iteration: 447 loss= 0.051567247013558276
Iteration: 448 loss= 0.051562782185334194
Iteration: 449 loss= 0.05155828724392349
Iteration: 450 loss= 0.05155376191366904
Iteration: 451 loss= 0.05154920591577759
Iteration: 452 loss= 0.05154461896827701
Iteration: 453 loss= 0.05154000078597279
Iteration: 454 loss= 0.051535351080403906
Iteration: 455 loss= 0.05153066955979783
Iteration: 456 loss= 0.05152595592902508
Iteration: 457 loss= 0.05152120988955278
Iteration: 458 loss= 0.05151643113939762
Iteration: 459 loss= 0.05151161937307803
Iteration: 460 loss= 0.051506774281565616
Iteration: 461 loss= 0.0515018955522357
Iteration: 462 loss= 0.05149698286881722
Iteration: 463 loss= 0.05149203591134166
Iteration: 464 loss= 0.05148705435609126
Iteration: 465 loss= 0.05148203787554638
Iteration: 466 loss= 0.0514769861383319
Iteration: 467 loss= 0.05147189880916283
Iteration: 468 loss= 0.05146677554878905
Iteration: 469 loss= 0.05146161601393908
Iteration: 470 loss= 0.051456419857262924
Iteration: 471 loss= 0.051451186727274015
Iteration: 472 loss= 0.05144591626829022
Iteration: 473 loss= 0.05144060812037371
Iteration: 474 loss= 0.051435261919270045
Iteration: 475 loss= 0.05142987729634615
Iteration: 476 loss= 0.051424453878527135
Iteration: 477 loss= 0.051418991288232296
Iteration: 478 loss= 0.051413489143309864
Iteration: 479 loss= 0.0514079470569707
Iteration: 480 loss= 0.05140236463772095
Iteration: 481 loss= 0.05139674148929338
Iteration: 482 loss= 0.05139107721057781
Iteration: 483 loss= 0.051385371395550106
Iteration: 484 loss= 0.05137962363320017
Iteration: 485 loss= 0.05137383350745855
Iteration: 486 loss= 0.05136800059712189
Iteration: 487 loss= 0.05136212447577712
Iteration: 488 loss= 0.051356204711724245
Iteration: 489 loss= 0.05135024086789788
Iteration: 490 loss= 0.05134423250178741
Iteration: 491 loss= 0.051338179165355886
Iteration: 492 loss= 0.0513320804049572
Iteration: 493 loss= 0.05132593576125222
Iteration: 494 loss= 0.051319744769123155
Iteration: 495 loss= 0.05131350695758672
Iteration: 496 loss= 0.05130722184970539
Iteration: 497 loss= 0.05130088896249747
Iteration: 498 loss= 0.05129450780684547
Iteration: 499 loss= 0.051288077887402715
Iteration: 500 loss= 0.051281598702498474
Iteration: 501 loss= 0.05127506974404151
Iteration: 502 loss= 0.05126849049742155
Iteration: 503 loss= 0.0512618604414094
Iteration: 504 loss= 0.05125517904805505
Iteration: 505 loss= 0.05124844578258411
Iteration: 506 loss= 0.051241660103292216
Iteration: 507 loss= 0.05123482146143765
Iteration: 508 loss= 0.0512279293011321
Iteration: 509 loss= 0.0512209830592293
Iteration: 510 loss= 0.05121398216521175
Iteration: 511 loss= 0.05120692604107542
Iteration: 512 loss= 0.05119981410121222
Iteration: 513 loss= 0.051192645752290475
Iteration: 514 loss= 0.0511854203931332
Iteration: 515 loss= 0.05117813741459404
Iteration: 516 loss= 0.05117079619943113
Iteration: 517 loss= 0.05116339612217841
Iteration: 518 loss= 0.05115593654901481
Iteration: 519 loss= 0.05114841683763077
Iteration: 520 loss= 0.05114083633709257
Iteration: 521 loss= 0.05113319438770388
Iteration: 522 loss= 0.05112549032086493
Iteration: 523 loss= 0.051117723458928926
Iteration: 524 loss= 0.05110989311505593
Iteration: 525 loss= 0.05110199859306385
Iteration: 526 loss= 0.051094039187276716
Iteration: 527 loss= 0.05108601418237013
Iteration: 528 loss= 0.051077922853213706
Iteration: 529 loss= 0.05106976446471064
Iteration: 530 loss= 0.051061538271634205
Iteration: 531 loss= 0.051053243518460974
Iteration: 532 loss= 0.05104487943920133
Iteration: 533 loss= 0.0510364452572261
Iteration: 534 loss= 0.05102794018509041
Iteration: 535 loss= 0.051019363424353946
Iteration: 536 loss= 0.05101071416539763
Iteration: 537 loss= 0.051001991587237144
Iteration: 538 loss= 0.05099319485733235
Iteration: 539 loss= 0.05098432313139353
Iteration: 540 loss= 0.050975375553183405
Iteration: 541 loss= 0.05096635125431565
Iteration: 542 loss= 0.050957249354049314
Iteration: 543 loss= 0.05094806895907923
Iteration: 544 loss= 0.050938809163322316
Iteration: 545 loss= 0.05092946904769975
Iteration: 546 loss= 0.0509200476799147
Iteration: 547 loss= 0.0509105441142259
Iteration: 548 loss= 0.05090095739121647
Iteration: 549 loss= 0.05089128653755834
Iteration: 550 loss= 0.05088153056577192
Iteration: 551 loss= 0.05087168847398095
Iteration: 552 loss= 0.050861759245662545
Iteration: 553 loss= 0.050851741849392014
Iteration: 554 loss= 0.050841635238582955
Iteration: 555 loss= 0.05083143835122145
Iteration: 556 loss= 0.05082115010959577
Iteration: 557 loss= 0.05081076942001971
Iteration: 558 loss= 0.050800295172550976
Iteration: 559 loss= 0.050789726240703464
Iteration: 560 loss= 0.050779061481153874
Iteration: 561 loss= 0.05076829973344217
Iteration: 562 loss= 0.050757439819665955
Iteration: 563 loss= 0.05074648054416867
Iteration: 564 loss= 0.05073542069322112
Iteration: 565 loss= 0.05072425903469667
Iteration: 566 loss= 0.05071299431773958
Iteration: 567 loss= 0.05070162527242647
Iteration: 568 loss= 0.05069015060942068
Iteration: 569 loss= 0.05067856901961959
Iteration: 570 loss= 0.050666879173794345
Iteration: 571 loss= 0.050655079722222135
Iteration: 572 loss= 0.05064316929431077
Iteration: 573 loss= 0.050631146498215186
Iteration: 574 loss= 0.050619009920446115
Iteration: 575 loss= 0.050606758125470025
Iteration: 576 loss= 0.05059438965530107
Iteration: 577 loss= 0.050581903029083955
Iteration: 578 loss= 0.05056929674266807
Iteration: 579 loss= 0.05055656926817249
Iteration: 580 loss= 0.05054371905354152
Iteration: 581 loss= 0.05053074452209081
Iteration: 582 loss= 0.050517644072043705
Iteration: 583 loss= 0.05050441607605732
Iteration: 584 loss= 0.0504910588807386
Iteration: 585 loss= 0.050477570806149764
Iteration: 586 loss= 0.050463950145302916
Iteration: 587 loss= 0.05045019516364366
Iteration: 588 loss= 0.05043630409852334
Iteration: 589 loss= 0.050422275158659824
Iteration: 590 loss= 0.050408106523586266
Iteration: 591 loss= 0.050393796343087716
Iteration: 592 loss= 0.050379342736625386
Iteration: 593 loss= 0.050364743792747906
Iteration: 594 loss= 0.05034999756848973
Iteration: 595 loss= 0.05033510208875595
Iteration: 596 loss= 0.05032005534569339
Iteration: 597 loss= 0.050304855298047686
Iteration: 598 loss= 0.05028949987050571
Iteration: 599 loss= 0.05027398695302346
Iteration: 600 loss= 0.05025831440013849
Iteration: 601 loss= 0.05024248003026694
Iteration: 602 loss= 0.05022648162498454
Iteration: 603 loss= 0.050210316928291185
Iteration: 604 loss= 0.050193983645858954
Iteration: 605 loss= 0.050177479444262534
Iteration: 606 loss= 0.050160801950192443
Iteration: 607 loss= 0.05014394874964972
Iteration: 608 loss= 0.05012691738712247
Iteration: 609 loss= 0.05010970536474299
Iteration: 610 loss= 0.050092310141425636
Iteration: 611 loss= 0.050074729131984574
Iteration: 612 loss= 0.050056959706230905
Iteration: 613 loss= 0.05003899918804894
Iteration: 614 loss= 0.05002084485445049
Iteration: 615 loss= 0.05000249393460744
Iteration: 616 loss= 0.04998394360886115
Iteration: 617 loss= 0.049965191007708694
Iteration: 618 loss= 0.049946233210765176
Iteration: 619 loss= 0.04992706724570138
Iteration: 620 loss= 0.04990769008715615
Iteration: 621 loss= 0.049888098655623075
Iteration: 622 loss= 0.049868289816310356
Iteration: 623 loss= 0.0498482603779735
Iteration: 624 loss= 0.04982800709172021
Iteration: 625 loss= 0.04980752664978616
Iteration: 626 loss= 0.04978681568428156
Iteration: 627 loss= 0.049765870765907466
Iteration: 628 loss= 0.0497446884026408
Iteration: 629 loss= 0.04972326503838763
Iteration: 630 loss= 0.04970159705160371
Iteration: 631 loss= 0.04967968075388121
Iteration: 632 loss= 0.049657512388501135
Iteration: 633 loss= 0.049635088128950164
Iteration: 634 loss= 0.04961240407740106
Iteration: 635 loss= 0.04958945626315581
Iteration: 636 loss= 0.04956624064105027
Iteration: 637 loss= 0.049542753089819466
Iteration: 638 loss= 0.04951898941042229
Iteration: 639 loss= 0.04949494532432481
Iteration: 640 loss= 0.04947061647174057
Iteration: 641 loss= 0.049445998409827475
Iteration: 642 loss= 0.04942108661083909
Iteration: 643 loss= 0.0493958764602301
Iteration: 644 loss= 0.049370363254714
Iteration: 645 loss= 0.04934454220027207
Iteration: 646 loss= 0.04931840841011209
Iteration: 647 loss= 0.04929195690257568
Iteration: 648 loss= 0.049265182598992534
Iteration: 649 loss= 0.04923808032148041
Iteration: 650 loss= 0.049210644790689186
Iteration: 651 loss= 0.04918287062348763
Iteration: 652 loss= 0.04915475233059105
Iteration: 653 loss= 0.04912628431412849
Iteration: 654 loss= 0.04909746086514767
Iteration: 655 loss= 0.04906827616105604
Iteration: 656 loss= 0.04903872426299592
Iteration: 657 loss= 0.04900879911315252
Iteration: 658 loss= 0.04897849453199226
Iteration: 659 loss= 0.04894780421543008
Iteration: 660 loss= 0.04891672173192343
Iteration: 661 loss= 0.04888524051949111
Iteration: 662 loss= 0.048853353882654944
Iteration: 663 loss= 0.048821054989301796
Iteration: 664 loss= 0.04878833686746427
Iteration: 665 loss= 0.04875519240201763
Iteration: 666 loss= 0.048721614331290554
Iteration: 667 loss= 0.04868759524358736
Iteration: 668 loss= 0.048653127573619656
Iteration: 669 loss= 0.04861820359884447
Iteration: 670 loss= 0.04858281543570663
Iteration: 671 loss= 0.04854695503578252
Iteration: 672 loss= 0.04851061418182297
Iteration: 673 loss= 0.048473784483691995
Iteration: 674 loss= 0.048436457374199104
Iteration: 675 loss= 0.04839862410482183
Iteration: 676 loss= 0.04836027574131595
Iteration: 677 loss= 0.04832140315921006
Iteration: 678 loss= 0.0482819970391816
Iteration: 679 loss= 0.04824204786231108
Iteration: 680 loss= 0.048201545905211425
Iteration: 681 loss= 0.048160481235028786
Iteration: 682 loss= 0.04811884370431187
Iteration: 683 loss= 0.048076622945746064
Iteration: 684 loss= 0.048033808366748885
Iteration: 685 loss= 0.047990389143923125
Iteration: 686 loss= 0.04794635421736411
Iteration: 687 loss= 0.04790169228481734
Iteration: 688 loss= 0.04785639179568242
Iteration: 689 loss= 0.047810440944859894
Iteration: 690 loss= 0.0477638276664364
Iteration: 691 loss= 0.04771653962720483
Iteration: 692 loss= 0.04766856422001475
Iteration: 693 loss= 0.0476198885569494
Iteration: 694 loss= 0.04757049946232485
Iteration: 695 loss= 0.04752038346550708
Iteration: 696 loss= 0.04746952679354273
Iteration: 697 loss= 0.04741791536359912
Iteration: 698 loss= 0.04736553477520917
Iteration: 699 loss= 0.0473123703023168
Iteration: 700 loss= 0.04725840688511822
Iteration: 701 loss= 0.04720362912169483
Iteration: 702 loss= 0.047148021259433265
Iteration: 703 loss= 0.047091567186227715
Iteration: 704 loss= 0.04703425042146043
Iteration: 705 loss= 0.04697605410675598
Iteration: 706 loss= 0.04691696099650448
Iteration: 707 loss= 0.04685695344814957
Iteration: 708 loss= 0.046796013412237145
Iteration: 709 loss= 0.04673412242222004
Iteration: 710 loss= 0.046671261584015016
Iteration: 711 loss= 0.046607411565307684
Iteration: 712 loss= 0.046542552584601875
Iteration: 713 loss= 0.046476664400009284
Iteration: 714 loss= 0.04640972629777643
Iteration: 715 loss= 0.0463417170805452
Iteration: 716 loss= 0.046272615055344225
Iteration: 717 loss= 0.04620239802130836
Iteration: 718 loss= 0.04613104325712379
Iteration: 719 loss= 0.04605852750819689
Iteration: 720 loss= 0.0459848269735452
Iteration: 721 loss= 0.045909917292409515
Iteration: 722 loss= 0.045833773530586416
Iteration: 723 loss= 0.045756370166481375
Iteration: 724 loss= 0.04567768107688324
Iteration: 725 loss= 0.04559767952246122
Iteration: 726 loss= 0.04551633813298696
Iteration: 727 loss= 0.0454336288922846
Iteration: 728 loss= 0.04534952312291313
Iteration: 729 loss= 0.045263991470585824
Iteration: 730 loss= 0.04517700388833382
Iteration: 731 loss= 0.04508852962042069
Iteration: 732 loss= 0.044998537186017644
Iteration: 733 loss= 0.04490699436264992
Iteration: 734 loss= 0.0448138681694264
Iteration: 735 loss= 0.04471912485006688
Iteration: 736 loss= 0.0446227298557432
Iteration: 737 loss= 0.04452464782775234
Iteration: 738 loss= 0.044424842580042534
Iteration: 739 loss= 0.044323277081615535
Iteration: 740 loss= 0.04421991343883136
Iteration: 741 loss= 0.044114712877644575
Iteration: 742 loss= 0.04400763572580476
Iteration: 743 loss= 0.04389864139505711
Iteration: 744 loss= 0.043787688363383426
Iteration: 745 loss= 0.043674734157327255
Iteration: 746 loss= 0.04355973533445235
Iteration: 747 loss= 0.04344264746598771
Iteration: 748 loss= 0.04332342511971818
Iteration: 749 loss= 0.04320202184318525
Iteration: 750 loss= 0.04307839014726876
Iteration: 751 loss= 0.04295248149022657
Iteration: 752 loss= 0.04282424626227707
Iteration: 753 loss= 0.04269363377081608
Iteration: 754 loss= 0.04256059222636859
Iteration: 755 loss= 0.04242506872938445
Iteration: 756 loss= 0.0422870092579963
Iteration: 757 loss= 0.04214635865686815
Iteration: 758 loss= 0.04200306062727435
Iteration: 759 loss= 0.04185705771855914
Iteration: 760 loss= 0.041708291321140636
Iteration: 761 loss= 0.04155670166123518
Iteration: 762 loss= 0.04140222779749216
Iteration: 763 loss= 0.04124480761974498
Iteration: 764 loss= 0.0410843778500988
Iteration: 765 loss= 0.0409208740465927
Iteration: 766 loss= 0.040754230609692355
Iteration: 767 loss= 0.04058438079188695
Iteration: 768 loss= 0.040411256710684906
Iteration: 769 loss= 0.04023478936532361
Iteration: 770 loss= 0.040054908657529864
Iteration: 771 loss= 0.039871543416692065
Iteration: 772 loss= 0.03968462142982787
Iteration: 773 loss= 0.03949406947675766
Iteration: 774 loss= 0.039299813370919603
Iteration: 775 loss= 0.039101778006289986
Iteration: 776 loss= 0.03889988741090057
Iteration: 777 loss= 0.03869406480747378
Iteration: 778 loss= 0.03848423268172674
Iteration: 779 loss= 0.038270312858925674
Iteration: 780 loss= 0.038052226589303156
Iteration: 781 loss= 0.03782989464298189
Iteration: 782 loss= 0.03760323741508068
Iteration: 783 loss= 0.03737217504170832
Iteration: 784 loss= 0.03713662752758291
Iteration: 785 loss= 0.036896514886042675
Iteration: 786 loss= 0.03665175729224282
Iteration: 787 loss= 0.03640227525035966
Iteration: 788 loss= 0.036147989775646025
Iteration: 789 loss= 0.03588882259220304
Iteration: 790 loss= 0.03562469634734966
Iteration: 791 loss= 0.035355534843482646
Iteration: 792 loss= 0.03508126328832592
Iteration: 793 loss= 0.03480180856446629
Iteration: 794 loss= 0.03451709951906395
Iteration: 795 loss= 0.03422706727460683
Iteration: 796 loss= 0.03393164556154839
Iteration: 797 loss= 0.033630771073626095
Iteration: 798 loss= 0.03332438384660166
Iteration: 799 loss= 0.03301242766109126
Iteration: 800 loss= 0.032694850470063784
Iteration: 801 loss= 0.032371604851474674
Iteration: 802 loss= 0.032042648486369806
Iteration: 803 loss= 0.03170794466263715
Iteration: 804 loss= 0.031367462804399456
Iteration: 805 loss= 0.031021179026828834
Iteration: 806 loss= 0.030669076715919452
Iteration: 807 loss= 0.030311147132477186
Iteration: 808 loss= 0.029947390039271906
Iteration: 809 loss= 0.02957781434994826
Iteration: 810 loss= 0.029202438797901565
Iteration: 811 loss= 0.02882129262289774
Iteration: 812 loss= 0.028434416272747554
Iteration: 813 loss= 0.028041862116837672
Iteration: 814 loss= 0.027643695167774627
Iteration: 815 loss= 0.027239993806814283
Iteration: 816 loss= 0.02683085050813326
Iteration: 817 loss= 0.026416372556353686
Iteration: 818 loss= 0.025996682751064308
Iteration: 819 loss= 0.025571920091398703
Iteration: 820 loss= 0.025142240433042487
Iteration: 821 loss= 0.024707817109359025
Iteration: 822 loss= 0.024268841507660385
Iteration: 823 loss= 0.023825523591022132
Iteration: 824 loss= 0.023378092355465015
Iteration: 825 loss= 0.022926796211823933
Iteration: 826 loss= 0.022471903281215115
Iteration: 827 loss= 0.022013701592720068
Iteration: 828 loss= 0.021552499171753853
Iteration: 829 loss= 0.02108862400760025
Iteration: 830 loss= 0.020622423888802338
Iteration: 831 loss= 0.020154266095519183
Iteration: 832 loss= 0.019684536938619098
Iteration: 833 loss= 0.019213641136198882
Iteration: 834 loss= 0.0187420010194113
Iteration: 835 loss= 0.018270055560963484
Iteration: 836 loss= 0.017798259221419567
Iteration: 837 loss= 0.01732708061050186
Iteration: 838 loss= 0.016857000962924616
Iteration: 839 loss= 0.01638851243089246
Iteration: 840 loss= 0.015922116198222813
Iteration: 841 loss= 0.015458320424065588
Iteration: 842 loss= 0.014997638027344067
Iteration: 843 loss= 0.014540584326264303
Iteration: 844 loss= 0.01408767455046653
Iteration: 845 loss= 0.01363942124654095
Iteration: 846 loss= 0.01319633160061514
Iteration: 847 loss= 0.012758904704454078
Iteration: 848 loss= 0.012327628793904269
Iteration: 849 loss= 0.011902978490474909
Iteration: 850 loss= 0.011485412078300498
Iteration: 851 loss= 0.011075368849598647
Iteration: 852 loss= 0.010673266551967842
Iteration: 853 loss= 0.010279498970421217
Iteration: 854 loss= 0.009894433675901908
Iteration: 855 loss= 0.009518409970174477
Iteration: 856 loss= 0.009151737054456774
Iteration: 857 loss= 0.00879469244599337
Iteration: 858 loss= 0.008447520663042812
Iteration: 859 loss= 0.008110432194543216
Iteration: 860 loss= 0.0077836027661399845
Iteration: 861 loss= 0.007467172909422233
Iteration: 862 loss= 0.00716124783624906
Iteration: 863 loss= 0.0068658976150841435
Iteration: 864 loss= 0.006581157641426458
Iteration: 865 loss= 0.00630702938985157
Iteration: 866 loss= 0.006043481430974831
Iteration: 867 loss= 0.0057904506929134705
Iteration: 868 loss= 0.005547843943639762
Iteration: 869 loss= 0.005315539468042755
Iteration: 870 loss= 0.005093388911589118
Iteration: 871 loss= 0.004881219261210981
Iteration: 872 loss= 0.004678834933446089
Iteration: 873 loss= 0.004486019939885519
Iteration: 874 loss= 0.004302540100607181
Iteration: 875 loss= 0.004128145277429426
Iteration: 876 loss= 0.003962571600441117
Iteration: 877 loss= 0.0038055436632746134
Iteration: 878 loss= 0.0036567766649065973
Iteration: 879 loss= 0.0035159784783141907
Iteration: 880 loss= 0.003382851629001213
Iteration: 881 loss= 0.003257095169164668
Iteration: 882 loss= 0.003138406436024222
Iteration: 883 loss= 0.0030264826855262174
Iteration: 884 loss= 0.002921022595204904
Iteration: 885 loss= 0.0028217276323939736
Iteration: 886 loss= 0.002728303286196863
Iteration: 887 loss= 0.002640460163621064
Iteration: 888 loss= 0.0025579149520432486
Iteration: 889 loss= 0.0024803912516921946
Iteration: 890 loss= 0.0024076202831139677
Iteration: 891 loss= 0.002339341475625101
Iteration: 892 loss= 0.0022753029435749615
Iteration: 893 loss= 0.0022152618578428146
Iteration: 894 loss= 0.00215898472040566
Iteration: 895 loss= 0.002106247550049489
Iteration: 896 loss= 0.00205683598737886
Iteration: 897 loss= 0.0020105453272288906
Iteration: 898 loss= 0.0019671804864202086
Iteration: 899 loss= 0.0019265559145407191
Iteration: 900 loss= 0.0018884954551063545
Iteration: 901 loss= 0.001852832164064252
Iteration: 902 loss= 0.0018194080921703657
Iteration: 903 loss= 0.0017880740373142244
Iteration: 904 loss= 0.0017586892723875742
Iteration: 905 loss= 0.0017311212538119781
Iteration: 906 loss= 0.0017052453153613924
Iteration: 907 loss= 0.0016809443514469243
Iteration: 908 loss= 0.0016581084935773098
Iteration: 909 loss= 0.0016366347832758657
Iteration: 910 loss= 0.0016164268443250422
Iteration: 911 loss= 0.0015973945568257936
Iteration: 912 loss= 0.0015794537352030202
Iteration: 913 loss= 0.00156252581195971
Iteration: 914 loss= 0.0015465375286825426
Iteration: 915 loss= 0.001531420635529393
Iteration: 916 loss= 0.0015171116001840876
Iteration: 917 loss= 0.001503551327044389
Iteration: 918 loss= 0.0014906848872148503
Iteration: 919 loss= 0.0014784612597046832
Iteration: 920 loss= 0.0014668330840811338
Iteration: 921 loss= 0.001455756424699246
Iteration: 922 loss= 0.0014451905465173729
Iteration: 923 loss= 0.0014350977024132844
Iteration: 924 loss= 0.0014254429318363553
Iteration: 925 loss= 0.0014161938705653018
Iteration: 926 loss= 0.0014073205712873756
Iteration: 927 loss= 0.0013987953346721268
Iteration: 928 loss= 0.0013905925505794732
Iteration: 929 loss= 0.0013826885490168797
Iteration: 930 loss= 0.0013750614604428717
Iteration: 931 loss= 0.0013676910850026615
Iteration: 932 loss= 0.0013605587702756098
Iteration: 933 loss= 0.001353647297113052
Iteration: 934 loss= 0.0013469407731472795
Iteration: 935 loss= 0.0013404245335581293
Iteration: 936 loss= 0.0013340850486920327
Iteration: 937 loss= 0.001327909838138627
Iteration: 938 loss= 0.0013218873908821846
Iteration: 939 loss= 0.0013160070911584732
Iteration: 940 loss= 0.0013102591496620029
Iteration: 941 loss= 0.0013046345397634764
Iteration: 942 loss= 0.0012991249384128084
Iteration: 943 loss= 0.001293722671418586
Iteration: 944 loss= 0.001288420662810545
Iteration: 945 loss= 0.0012832123880071248
Iteration: 946 loss= 0.0012780918305253862
Iteration: 947 loss= 0.001273053441985727
Iteration: 948 loss= 0.0012680921051781656
Iteration: 949 loss= 0.0012632030999711562
Iteration: 950 loss= 0.0012583820718574223
Iteration: 951 loss= 0.0012536250029443234
Iteration: 952 loss= 0.0012489281852087202
Iteration: 953 loss= 0.0012442881958480453
Iteration: 954 loss= 0.0012397018745708144
Iteration: 955 loss= 0.0012351663026801117
Iteration: 956 loss= 0.0012306787838141007
Iteration: 957 loss= 0.00122623682621671
Iteration: 958 loss= 0.0012218381264210813
Iteration: 959 loss= 0.0012174805542363182
Iteration: 960 loss= 0.00121316213893636
Iteration: 961 loss= 0.0012088810565570297
Iteration: 962 loss= 0.001204635618214278
Iteration: 963 loss= 0.001200424259363132
Iteration: 964 loss= 0.0011962455299229257
Iteration: 965 loss= 0.0011920980851999096
Iteration: 966 loss= 0.0011879806775437634
Iteration: 967 loss= 0.0011838921486792243
Iteration: 968 loss= 0.0011798314226587185
Iteration: 969 loss= 0.0011757974993859678
Iteration: 970 loss= 0.0011717894486645373
Iteration: 971 loss= 0.0011678064047288717
Iteration: 972 loss= 0.0011638475612186822
Iteration: 973 loss= 0.0011599121665606697
Iteration: 974 loss= 0.0011559995197244514
Iteration: 975 loss= 0.001152108966322172
Iteration: 976 loss= 0.0011482398950237462
Iteration: 977 loss= 0.0011443917342618746
Iteration: 978 loss= 0.001140563949203213
Iteration: 979 loss= 0.001136756038963738
Iteration: 980 loss= 0.0011329675340484393
Iteration: 981 loss= 0.0011291979939967883
Iteration: 982 loss= 0.0011254470052171725
Iteration: 983 loss= 0.0011217141789946702
Iteration: 984 loss= 0.001117999149658079
Iteration: 985 loss= 0.0011143015728929005
Iteration: 986 loss= 0.0011106211241884597
Iteration: 987 loss= 0.001106957497408028
Iteration: 988 loss= 0.0011033104034718782
Iteration: 989 loss= 0.0010996795691440072
Iteration: 990 loss= 0.0010960647359140215
Iteration: 991 loss= 0.001092465658966314
Iteration: 992 loss= 0.001088882106229499
Iteration: 993 loss= 0.0010853138574994012
Iteration: 994 loss= 0.001081760703629735
Iteration: 995 loss= 0.0010782224457847925
Iteration: 996 loss= 0.0010746988947492547
Iteration: 997 loss= 0.0010711898702902814
Iteration: 998 loss= 0.0010676952005678761
Iteration: 999 loss= 0.001064214721589374
It took 0.49199986457824707  sec
it must be 0 : -0.016412020632210443
it must be 0.1 : 0.08634728285674452
it must be 0.2 : 0.20523703439553675
it must be 0.3 : 0.3228928639384614
it must be 0.4 : 0.4401599701119392
it must be 0.5 : 0.5242575361495077
it must be 0.6 : 0.5834533555076685
it must be 0.7 : 0.6290675376563587
See you later!
